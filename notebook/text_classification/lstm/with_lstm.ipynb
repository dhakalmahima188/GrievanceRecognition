{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepali_stopwords = set(stopwords.words('nepali'))\n",
    "english_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove specified characters\n",
    "    text = re.sub('[#\\\\/।(),०-९<<?!,—–’‘:\\u200d]', '', text)\n",
    "    # Strip double quotes\n",
    "    text = text.strip('\"')\n",
    "\n",
    "    # Tokenize the text\n",
    "    words=word_tokenize(text)\n",
    "    # Remove stop words for both Nepali and English\n",
    "    filtered_words = [word for word in words if word.lower() not in nepali_stopwords and word.lower() not in english_stopwords]\n",
    "    # Join the filtered words to form the processed text\n",
    "    processed_text = ' '.join(filtered_words)\n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 21:52:29.585706: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa1ac00d290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-08 21:52:29.585740: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-12-08 21:52:29.598313: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-08 21:52:29.670481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2023-12-08 21:52:29.766541: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 93s 339ms/step - loss: 1.8714 - accuracy: 0.3351 - val_loss: 1.6782 - val_accuracy: 0.4349\n",
      "Epoch 2/10\n",
      "259/259 [==============================] - 74s 286ms/step - loss: 1.4130 - accuracy: 0.4917 - val_loss: 1.3519 - val_accuracy: 0.5191\n",
      "Epoch 3/10\n",
      "259/259 [==============================] - 68s 262ms/step - loss: 1.1042 - accuracy: 0.6090 - val_loss: 1.3374 - val_accuracy: 0.5278\n",
      "Epoch 4/10\n",
      "259/259 [==============================] - 64s 248ms/step - loss: 0.8735 - accuracy: 0.6985 - val_loss: 1.3796 - val_accuracy: 0.5331\n",
      "Epoch 5/10\n",
      "259/259 [==============================] - 64s 245ms/step - loss: 0.6479 - accuracy: 0.7880 - val_loss: 1.2917 - val_accuracy: 0.6057\n",
      "Epoch 6/10\n",
      "259/259 [==============================] - 63s 244ms/step - loss: 0.4871 - accuracy: 0.8452 - val_loss: 1.3919 - val_accuracy: 0.6047\n",
      "Epoch 7/10\n",
      "259/259 [==============================] - 63s 245ms/step - loss: 0.3972 - accuracy: 0.8719 - val_loss: 1.3773 - val_accuracy: 0.6139\n",
      "Epoch 8/10\n",
      "259/259 [==============================] - 62s 240ms/step - loss: 0.2926 - accuracy: 0.9032 - val_loss: 1.4887 - val_accuracy: 0.6193\n",
      "Epoch 9/10\n",
      "259/259 [==============================] - 63s 244ms/step - loss: 0.2516 - accuracy: 0.9217 - val_loss: 1.5845 - val_accuracy: 0.5980\n",
      "Epoch 10/10\n",
      "259/259 [==============================] - 63s 242ms/step - loss: 0.2060 - accuracy: 0.9370 - val_loss: 1.6182 - val_accuracy: 0.6120\n",
      "65/65 [==============================] - 2s 26ms/step - loss: 1.6182 - accuracy: 0.6120\n",
      "Accuracy: 61.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadika/Documents/Major/major_dataset_basanta_sir/venv/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nadika/Documents/Major/major_dataset_basanta_sir/with_lstm.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nadika/Documents/Major/major_dataset_basanta_sir/with_lstm.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# Save the Tokenizer and Label Encoder\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nadika/Documents/Major/major_dataset_basanta_sir/with_lstm.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtokenizer.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m tokenizer_file:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nadika/Documents/Major/major_dataset_basanta_sir/with_lstm.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     tokenizer_file\u001b[39m.\u001b[39;49mwrite(tokenizer\u001b[39m.\u001b[39;49mto_json())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nadika/Documents/Major/major_dataset_basanta_sir/with_lstm.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlabel_encoder.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m encoder_file:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nadika/Documents/Major/major_dataset_basanta_sir/with_lstm.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     encoder_file\u001b[39m.\u001b[39mwrite(le\u001b[39m.\u001b[39mto_json())\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the preprocessed data\n",
    "df_final = pd.read_excel(\"dataset/updated_text_data.xlsx\")\n",
    "df_final['गुनासो'] = df_final['गुनासो'].apply(preprocess_text)\n",
    "\n",
    "# Tokenization and Padding\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df_final['गुनासो'])\n",
    "X_seq = tokenizer.texts_to_sequences(df_final['गुनासो'])\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_len)\n",
    "\n",
    "# Encoding Labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df_final['गुनासो वर्ग'])\n",
    "\n",
    "# Define the LSTM model\n",
    "embedding_dim = 50\n",
    "lstm_units = 100\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(units=lstm_units, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Split the data and train the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42, stratify=y)\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the model\n",
    "model.save(\"lstm_model.h5\")\n",
    "\n",
    "# Save the Tokenizer and Label Encoder\n",
    "with open('tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "    tokenizer_file.write(tokenizer.to_json())\n",
    "\n",
    "with open('label_encoder.pkl', 'wb') as encoder_file:\n",
    "    encoder_file.write(le.to_json())\n",
    "\n",
    "# Make predictions on new data\n",
    "new_text = 'मेरो घर अगाडी सडक दुर्घटना भएको ले अबरुधा छ | बाटो कहिले बन्छ ?'\n",
    "new_text_seq = tokenizer.texts_to_sequences([new_text])\n",
    "new_text_padded = pad_sequences(new_text_seq, maxlen=max_len)\n",
    "predicted_class = np.argmax(model.predict(new_text_padded), axis=-1)\n",
    "decoded_data = le.inverse_transform(predicted_class)\n",
    "print(decoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
